{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import gc\n",
    "import os\n",
    "import ast\n",
    "import sys\n",
    "import configparser\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.callbacks import History\n",
    "from keras.layers import Reshape\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import keras\n",
    "from keras import backend as K\n",
    "\n",
    "from audiomanip.audiostruct import AudioStruct\n",
    "from audiomanip.audiomodels import ModelZoo\n",
    "from audiomanip.audioutils import AudioUtils\n",
    "from audiomanip.audioutils import MusicDataGenerator\n",
    "\n",
    "# Disable TF warnings about speed up\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL']='2'\n",
    "\n",
    "\n",
    "def main():\n",
    "  # Parse config file\n",
    "  config = configparser.ConfigParser()\n",
    "  config.read('params.ini')\n",
    "\n",
    "  #Configuration\n",
    "  GTZAN_FOLDER = config['FILE_READ']['GTZAN_FOLDER']\n",
    "  MODEL_PATH = config['FILE_READ']['SAVE_MODEL']\n",
    "  SAVE_NPY = ast.literal_eval(config['FILE_READ']['SAVE_NPY'])\n",
    "  TENSORBOARD_LOG_DIR = config['FILE_READ']['TENSORBOARD_LOG_DIR']\n",
    "  EXEC_TIMES = int(config['PARAMETERS_MODEL']['EXEC_TIMES'])\n",
    "  CNN_TYPE = config['PARAMETERS_MODEL']['CNN_TYPE']\n",
    "  OPTIMIZER = config['PARAMETERS_MODEL']['OPTIMIZER']\n",
    "\n",
    "  ## CNN hyperparameters\n",
    "  batch_size = int(config['PARAMETERS_MODEL']['BATCH_SIZE'])\n",
    "  epochs = int(config['PARAMETERS_MODEL']['EPOCHS'])\n",
    "\n",
    "  if not ((CNN_TYPE == '1D') or (CNN_TYPE == '2D') or (CNN_TYPE == 'RNN')):\n",
    "    raise ValueError('Argument Invalid: The options are 1D or 2D or RNN for CNN_TYPE')\n",
    "\n",
    "  # Read data\n",
    "  data_type = config['FILE_READ']['TYPE']\n",
    "  input_shape = (1280, 128)\n",
    "  print(\"data_type: %s\" % data_type)\n",
    "\n",
    "  ## Read the .au files\n",
    "  if data_type == 'AUDIO_FILES':\n",
    "    song_rep = AudioStruct(GTZAN_FOLDER, config)\n",
    "    songs, genres = song_rep.getdata()\n",
    "\n",
    "    # Save the audio files as npy files to read faster next time\n",
    "    if SAVE_NPY:\n",
    "      np.save(GTZAN_FOLDER + 'songs.npy', songs)\n",
    "      np.save(GTZAN_FOLDER + 'genres.npy', genres)\n",
    "\n",
    "  ## Read from npy file\n",
    "  elif data_type == 'NPY':\n",
    "    songs = np.load(GTZAN_FOLDER + 'songs.npy')\n",
    "    genres = np.load(GTZAN_FOLDER + 'genres.npy')\n",
    "\n",
    "  ## Not valid datatype\n",
    "  else:\n",
    "    raise ValueError('Argument Invalid: The options are AUDIO_FILES or NPY for data_type')\n",
    "\n",
    "  print(\"Original songs array shape: {0}\".format(songs.shape))\n",
    "  print(\"Original genre array shape: {0}\".format(genres.shape))\n",
    "\n",
    "  # Train multiple times and get mean score\n",
    "  val_acc = []\n",
    "  test_history = []\n",
    "  test_acc = []\n",
    "  test_acc_mvs = []\n",
    "\n",
    "  best_acc = 0\n",
    "  best_cnn = None\n",
    "\n",
    "\n",
    "  # Tensorboard Callback Definition\n",
    "  K.set_learning_phase(1) #set learning phase\n",
    "\n",
    "  for x in range(EXEC_TIMES):\n",
    "    keras.backend.clear_session()\n",
    "    tbCallBack = keras.callbacks.TensorBoard(log_dir=TENSORBOARD_LOG_DIR,\n",
    "     histogram_freq=3,\n",
    "     write_grads=True,\n",
    "     write_graph=True,\n",
    "     write_images=True)\n",
    "\n",
    "    # Split the dataset into training and test\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "      songs, genres, test_size=0.1, stratify=genres)\n",
    "\n",
    "    # Split training set into training and validation\n",
    "    X_train, X_Val, y_train, y_val = train_test_split(\n",
    "      X_train, y_train, test_size=1/6, stratify=y_train)\n",
    "\n",
    "    # split the train, test and validation data in size 128x128\n",
    "    X_Val, y_val = AudioUtils().splitsongs_melspect(X_Val, y_val, CNN_TYPE)\n",
    "    X_test, y_test = AudioUtils().splitsongs_melspect(X_test, y_test, CNN_TYPE)\n",
    "    X_train, y_train = AudioUtils().splitsongs_melspect(X_train, y_train, CNN_TYPE)\n",
    "\n",
    "    # Construct the model\n",
    "    if CNN_TYPE == '1D':\n",
    "      cnn = ModelZoo.cnn_melspect_1D(input_shape)\n",
    "    elif CNN_TYPE == '2D':\n",
    "      cnn = ModelZoo.cnn_melspect_2D((*input_shape, 1))\n",
    "    elif CNN_TYPE == 'RNN':\n",
    "      cnn = ModelZoo.crnn_melspect_2D((*input_shape, 1))\n",
    "\n",
    "    print(\"\\nTrain shape: {0}\".format(X_train.shape))\n",
    "    print(\"Validation shape: {0}\".format(X_Val.shape))\n",
    "    print(\"Test shape: {0}\\n\".format(X_test.shape))\n",
    "    print(\"Size of the CNN: %s\\n\" % cnn.count_params())\n",
    "\n",
    "    # Optimizers\n",
    "    if OPTIMIZER == 'sgd':\n",
    "      opt = keras.optimizers.SGD(lr=0.001, momentum=0.9, decay=1e-5, nesterov=True)\n",
    "    elif OPTIMIZER == 'adam':\n",
    "      opt = keras.optimizers.Adam(lr=5e-3) # lr=0.001 #, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=1e-5)\n",
    "\n",
    "    # Compiler for the model\n",
    "    cnn.compile(loss=keras.losses.categorical_crossentropy, #loss=keras.losses.categorical_crossentropy,\n",
    "      optimizer=opt,\n",
    "      metrics=['accuracy'])\n",
    "\n",
    "    # Early stop\n",
    "    earlystop = keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "      min_delta=0,\n",
    "      patience=2,\n",
    "      verbose=0,\n",
    "      mode='auto')\n",
    "\n",
    "    # Fit the model\n",
    "    history = cnn.fit(X_train, y_train,\n",
    "      batch_size=batch_size,\n",
    "      epochs=epochs,\n",
    "      verbose=1,\n",
    "      validation_data=(X_Val, y_val),\n",
    "      callbacks = [earlystop])\n",
    "    print('history: ', history.history['acc'])\n",
    "\n",
    "    score = cnn.evaluate(X_test, y_test, verbose=0)\n",
    "    score_val = cnn.evaluate(X_Val, y_val, verbose=0)\n",
    "\n",
    "    # Majority Voting System\n",
    "    pred_org_values = cnn.predict(X_test)\n",
    "    pred_label_values = np.argmax(pred_org_values, axis = 1)\n",
    "    mvs_truth, mvs_res = AudioUtils().voting(np.argmax(y_test, axis = 1), pred_label_values)\n",
    "    acc_mvs = accuracy_score(mvs_truth, mvs_res)\n",
    "    mvs_roc_auc = roc_auc_score(y_test, pred_org_values)\n",
    "\n",
    "\n",
    "    # Save metrics\n",
    "    val_acc.append(score_val[1])\n",
    "    test_acc.append(score[1])\n",
    "    test_history.append(history)\n",
    "    test_acc_mvs.append(acc_mvs)\n",
    "\n",
    "    # Print metrics\n",
    "    print('Test accuracy:', score[1])\n",
    "    print('Test accuracy for Majority Voting System:', acc_mvs)\n",
    "    print('Test auc_roc_score for Majority Voting System:', mvs_roc_auc)\n",
    "\n",
    "    # Print the confusion matrix for Voting System\n",
    "    cm = confusion_matrix(mvs_truth, mvs_res)\n",
    "    print(cm)\n",
    "\n",
    "    # Records Best Model\n",
    "    if (best_acc < acc_mvs):\n",
    "        best_acc = acc_mvs\n",
    "        best_cnn = cnn\n",
    "        best_history = history\n",
    "        print('best_history:', best_history.history['acc'])\n",
    "        print('best_acc changed:', best_acc)\n",
    "\n",
    "  # Print the statistics\n",
    "  print(\"Validation accuracy - mean: %s, std: %s\" % (np.mean(val_acc), np.std(val_acc)))\n",
    "  print(\"Test accuracy - mean: %s, std: %s\" % (np.mean(test_acc), np.std(test_acc)))\n",
    "  print(\"Test accuracy MVS - mean: %s, std: %s\" % (np.mean(test_acc_mvs), np.std(test_acc_mvs)))\n",
    "\n",
    "  # summarize history for accuracy\n",
    "  print('best_acc:', best_acc)\n",
    "  plt.plot(best_history.history['acc'])\n",
    "  plt.plot(best_history.history['val_acc'])\n",
    "  plt.title('model accuracy')\n",
    "  plt.ylabel('accuracy')\n",
    "  plt.xlabel('epoch')\n",
    "  plt.legend(['train', 'test'], loc='upper left')\n",
    "  plt.show()\n",
    "\n",
    "  # summarize history for loss\n",
    "  plt.plot(best_history.history['loss'])\n",
    "  plt.plot(best_history.history['val_loss'])\n",
    "  plt.title('model loss')\n",
    "  plt.ylabel('loss')\n",
    "  plt.xlabel('epoch')\n",
    "  plt.legend(['train', 'test'], loc='upper left')\n",
    "  plt.show()\n",
    "\n",
    "  # Save the model\n",
    "  best_cnn.save(MODEL_PATH)\n",
    "\n",
    "  # Free memory\n",
    "  del songs\n",
    "  del genres\n",
    "  gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_type: NPY\n",
      "Original songs array shape: (1000, 1280, 128)\n",
      "Original genre array shape: (1000, 10)\n",
      "original X shape:  (150, 1280, 128)\n",
      "2D X shape:  (150, 1280, 128, 1)\n",
      "original X shape:  (100, 1280, 128)\n",
      "2D X shape:  (100, 1280, 128, 1)\n",
      "original X shape:  (750, 1280, 128)\n",
      "2D X shape:  (750, 1280, 128, 1)\n",
      "input_shape:  (1280, 128, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/a1100498/vision_mmt_classification/src/audiomanip/audiomodels.py:167: UserWarning: Update your `BatchNormalization` call to the Keras 2 API: `BatchNormalization(axis=1, name=\"bn1\")`\n",
      "  bn1 = BatchNormalization(axis=channel_axis, mode=0, name='bn1')(conv1)\n",
      "/Users/a1100498/vision_mmt_classification/src/audiomanip/audiomodels.py:174: UserWarning: Update your `BatchNormalization` call to the Keras 2 API: `BatchNormalization(axis=1, name=\"bn2\")`\n",
      "  bn2 = BatchNormalization(axis=channel_axis, mode=0, name='bn2')(conv2)\n",
      "/Users/a1100498/vision_mmt_classification/src/audiomanip/audiomodels.py:181: UserWarning: Update your `BatchNormalization` call to the Keras 2 API: `BatchNormalization(axis=1, name=\"bn3\")`\n",
      "  bn3 = BatchNormalization(axis=channel_axis, mode=0, name='bn3')(conv3)\n",
      "/Users/a1100498/vision_mmt_classification/src/audiomanip/audiomodels.py:188: UserWarning: Update your `BatchNormalization` call to the Keras 2 API: `BatchNormalization(axis=1, name=\"bn4\")`\n",
      "  bn4 = BatchNormalization(axis=channel_axis, mode=0, name='bn4')(conv4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dr4shape: (None, 25, 1, 128)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 1280, 128, 1)      0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, 1278, 126, 64)     640       \n",
      "_________________________________________________________________\n",
      "bn1 (BatchNormalization)     (None, 1278, 126, 64)     5112      \n",
      "_________________________________________________________________\n",
      "elu_1 (ELU)                  (None, 1278, 126, 64)     0         \n",
      "_________________________________________________________________\n",
      "pool1 (MaxPooling2D)         (None, 639, 63, 64)       0         \n",
      "_________________________________________________________________\n",
      "dropout1 (Dropout)           (None, 639, 63, 64)       0         \n",
      "_________________________________________________________________\n",
      "conv2 (Conv2D)               (None, 637, 61, 128)      73856     \n",
      "_________________________________________________________________\n",
      "bn2 (BatchNormalization)     (None, 637, 61, 128)      2548      \n",
      "_________________________________________________________________\n",
      "elu_2 (ELU)                  (None, 637, 61, 128)      0         \n",
      "_________________________________________________________________\n",
      "pool2 (MaxPooling2D)         (None, 318, 30, 128)      0         \n",
      "_________________________________________________________________\n",
      "dropout2 (Dropout)           (None, 318, 30, 128)      0         \n",
      "_________________________________________________________________\n",
      "conv3 (Conv2D)               (None, 316, 28, 128)      147584    \n",
      "_________________________________________________________________\n",
      "bn3 (BatchNormalization)     (None, 316, 28, 128)      1264      \n",
      "_________________________________________________________________\n",
      "elu_3 (ELU)                  (None, 316, 28, 128)      0         \n",
      "_________________________________________________________________\n",
      "pool3 (MaxPooling2D)         (None, 105, 9, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout3 (Dropout)           (None, 105, 9, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv4 (Conv2D)               (None, 103, 7, 128)       147584    \n",
      "_________________________________________________________________\n",
      "bn4 (BatchNormalization)     (None, 103, 7, 128)       412       \n",
      "_________________________________________________________________\n",
      "elu_4 (ELU)                  (None, 103, 7, 128)       0         \n",
      "_________________________________________________________________\n",
      "pool4 (MaxPooling2D)         (None, 25, 1, 128)        0         \n",
      "_________________________________________________________________\n",
      "dropout4 (Dropout)           (None, 25, 1, 128)        0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 25, 128)           0         \n",
      "_________________________________________________________________\n",
      "gru1 (GRU)                   (None, 25, 32)            15456     \n",
      "_________________________________________________________________\n",
      "gru2 (GRU)                   (None, 32)                6240      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 401,026\n",
      "Trainable params: 396,358\n",
      "Non-trainable params: 4,668\n",
      "_________________________________________________________________\n",
      "\n",
      "Train shape: (750, 1280, 128, 1)\n",
      "Validation shape: (150, 1280, 128, 1)\n",
      "Test shape: (100, 1280, 128, 1)\n",
      "\n",
      "Size of the CNN: 401026\n",
      "\n",
      "Train on 750 samples, validate on 150 samples\n",
      "Epoch 1/100\n",
      "750/750 [==============================] - 1552s 2s/step - loss: 2.2266 - acc: 0.1520 - val_loss: 2.1437 - val_acc: 0.2200\n",
      "Epoch 2/100\n",
      "750/750 [==============================] - 1661s 2s/step - loss: 2.0451 - acc: 0.2040 - val_loss: 1.9931 - val_acc: 0.2867\n",
      "Epoch 3/100\n",
      "750/750 [==============================] - 1648s 2s/step - loss: 1.9928 - acc: 0.2360 - val_loss: 1.9192 - val_acc: 0.2133\n",
      "Epoch 4/100\n",
      "750/750 [==============================] - 1775s 2s/step - loss: 1.9195 - acc: 0.2440 - val_loss: 2.0453 - val_acc: 0.2600\n",
      "Epoch 5/100\n",
      "750/750 [==============================] - 1698s 2s/step - loss: 1.8756 - acc: 0.2733 - val_loss: 1.9157 - val_acc: 0.3000\n",
      "Epoch 6/100\n",
      "750/750 [==============================] - 1784s 2s/step - loss: 1.8236 - acc: 0.2533 - val_loss: 1.9641 - val_acc: 0.2800\n",
      "Epoch 7/100\n",
      "736/750 [============================>.] - ETA: 30s - loss: 1.8562 - acc: 0.2609 "
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "  main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = configparser.ConfigParser()\n",
    "config.read('params.ini')\n",
    "\n",
    "#Configuration\n",
    "GTZAN_FOLDER = config['FILE_READ']['GTZAN_FOLDER']\n",
    "MODEL_PATH = config['FILE_READ']['SAVE_MODEL']\n",
    "SAVE_NPY = ast.literal_eval(config['FILE_READ']['SAVE_NPY'])\n",
    "TENSORBOARD_LOG_DIR = config['FILE_READ']['TENSORBOARD_LOG_DIR']\n",
    "EXEC_TIMES = int(config['PARAMETERS_MODEL']['EXEC_TIMES'])\n",
    "CNN_TYPE = config['PARAMETERS_MODEL']['CNN_TYPE']\n",
    "OPTIMIZER = config['PARAMETERS_MODEL']['OPTIMIZER']\n",
    "\n",
    "## CNN hyperparameters\n",
    "batch_size = int(config['PARAMETERS_MODEL']['BATCH_SIZE'])\n",
    "epochs = int(config['PARAMETERS_MODEL']['EPOCHS'])\n",
    "\n",
    "if not ((CNN_TYPE == '1D') or (CNN_TYPE == '2D') or (CNN_TYPE == 'RNN')):\n",
    "  raise ValueError('Argument Invalid: The options are 1D or 2D or RNN for CNN_TYPE')\n",
    "\n",
    "# Read data\n",
    "data_type = config['FILE_READ']['TYPE']\n",
    "input_shape = (128, 128)\n",
    "print(\"data_type: %s\" % data_type)\n",
    "\n",
    "## Read the .au files\n",
    "if data_type == 'AUDIO_FILES':\n",
    "  song_rep = AudioStruct(GTZAN_FOLDER)\n",
    "  songs, genres = song_rep.getdata()\n",
    "\n",
    "  # Save the audio files as npy files to read faster next time\n",
    "  if SAVE_NPY:\n",
    "    np.save(GTZAN_FOLDER + 'songs.npy', songs)\n",
    "    np.save(GTZAN_FOLDER + 'genres.npy', genres)\n",
    "\n",
    "## Read from npy file\n",
    "elif data_type == 'NPY':\n",
    "  songs = np.load(GTZAN_FOLDER + 'songs.npy')\n",
    "  genres = np.load(GTZAN_FOLDER + 'genres.npy')\n",
    "\n",
    "## Not valid datatype\n",
    "else:\n",
    "  raise ValueError('Argument Invalid: The options are AUDIO_FILES or NPY for data_type')\n",
    "\n",
    "print(\"Original songs array shape: {0}\".format(songs.shape))\n",
    "print(\"Original genre array shape: {0}\".format(genres.shape))\n",
    "\n",
    "# Train multiple times and get mean score\n",
    "val_acc = []\n",
    "test_history = []\n",
    "test_acc = []\n",
    "test_acc_mvs = []\n",
    "\n",
    "best_acc = 0\n",
    "best_cnn = None\n",
    "best_history = None\n",
    "\n",
    "# Tensorboard Callback Definition\n",
    "K.set_learning_phase(1) #set learning phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original X shape:  (1500, 128, 128)\n",
      "2D X shape:  (1500, 128, 128, 1)\n",
      "original X shape:  (1000, 128, 128)\n",
      "2D X shape:  (1000, 128, 128, 1)\n",
      "original X shape:  (7500, 128, 128)\n",
      "2D X shape:  (7500, 128, 128, 1)\n",
      "input_shape:  (128, 128, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/a1100498/vision_mmt_classification/src/audiomanip/audiomodels.py:167: UserWarning: Update your `BatchNormalization` call to the Keras 2 API: `BatchNormalization(axis=1, name=\"bn1\")`\n",
      "  bn1 = BatchNormalization(axis=channel_axis, mode=0, name='bn1')(conv1)\n",
      "/Users/a1100498/vision_mmt_classification/src/audiomanip/audiomodels.py:174: UserWarning: Update your `BatchNormalization` call to the Keras 2 API: `BatchNormalization(axis=1, name=\"bn2\")`\n",
      "  bn2 = BatchNormalization(axis=channel_axis, mode=0, name='bn2')(conv2)\n",
      "/Users/a1100498/vision_mmt_classification/src/audiomanip/audiomodels.py:181: UserWarning: Update your `BatchNormalization` call to the Keras 2 API: `BatchNormalization(axis=1, name=\"bn3\")`\n",
      "  bn3 = BatchNormalization(axis=channel_axis, mode=0, name='bn3')(conv3)\n",
      "/Users/a1100498/vision_mmt_classification/src/audiomanip/audiomodels.py:188: UserWarning: Update your `BatchNormalization` call to the Keras 2 API: `BatchNormalization(axis=1, name=\"bn4\")`\n",
      "  bn4 = BatchNormalization(axis=channel_axis, mode=0, name='bn4')(conv4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 128, 128, 1)       0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, 126, 126, 64)      640       \n",
      "_________________________________________________________________\n",
      "bn1 (BatchNormalization)     (None, 126, 126, 64)      504       \n",
      "_________________________________________________________________\n",
      "elu_1 (ELU)                  (None, 126, 126, 64)      0         \n",
      "_________________________________________________________________\n",
      "pool1 (MaxPooling2D)         (None, 63, 63, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout1 (Dropout)           (None, 63, 63, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2 (Conv2D)               (None, 61, 61, 128)       73856     \n",
      "_________________________________________________________________\n",
      "bn2 (BatchNormalization)     (None, 61, 61, 128)       244       \n",
      "_________________________________________________________________\n",
      "elu_2 (ELU)                  (None, 61, 61, 128)       0         \n",
      "_________________________________________________________________\n",
      "pool2 (MaxPooling2D)         (None, 30, 30, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout2 (Dropout)           (None, 30, 30, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv3 (Conv2D)               (None, 28, 28, 128)       147584    \n",
      "_________________________________________________________________\n",
      "bn3 (BatchNormalization)     (None, 28, 28, 128)       112       \n",
      "_________________________________________________________________\n",
      "elu_3 (ELU)                  (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "pool3 (MaxPooling2D)         (None, 9, 9, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout3 (Dropout)           (None, 9, 9, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv4 (Conv2D)               (None, 7, 7, 128)         147584    \n",
      "_________________________________________________________________\n",
      "bn4 (BatchNormalization)     (None, 7, 7, 128)         28        \n",
      "_________________________________________________________________\n",
      "elu_4 (ELU)                  (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "pool4 (MaxPooling2D)         (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout4 (Dropout)           (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 1, 128)            0         \n",
      "_________________________________________________________________\n",
      "gru1 (GRU)                   (None, 1, 32)             15456     \n",
      "_________________________________________________________________\n",
      "gru2 (GRU)                   (None, 32)                6240      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 392,578\n",
      "Trainable params: 392,134\n",
      "Non-trainable params: 444\n",
      "_________________________________________________________________\n",
      "\n",
      "Train shape: (7500, 128, 128, 1)\n",
      "Validation shape: (1500, 128, 128, 1)\n",
      "Test shape: (1000, 128, 128, 1)\n",
      "\n",
      "Size of the CNN: 392578\n",
      "\n",
      "Train on 7500 samples, validate on 1500 samples\n",
      "Epoch 1/1\n",
      "7500/7500 [==============================] - 1457s 194ms/step - loss: 0.3163 - acc: 0.8980 - val_loss: 0.2720 - val_acc: 0.9029\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "multiclass format is not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-16b78eb0ad67>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0mmvs_truth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmvs_res\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAudioUtils\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvoting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0macc_mvs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmvs_truth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmvs_res\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m \u001b[0mmvs_roc_auc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmvs_truth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmvs_res\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;31m# Save metrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/env/fma_tensorflow/lib/python3.6/site-packages/sklearn/metrics/ranking.py\u001b[0m in \u001b[0;36mroc_auc_score\u001b[0;34m(y_true, y_score, average, sample_weight)\u001b[0m\n\u001b[1;32m    275\u001b[0m     return _average_binary_score(\n\u001b[1;32m    276\u001b[0m         \u001b[0m_binary_roc_auc_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m         sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/env/fma_tensorflow/lib/python3.6/site-packages/sklearn/metrics/base.py\u001b[0m in \u001b[0;36m_average_binary_score\u001b[0;34m(binary_metric, y_true, y_score, average, sample_weight)\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0my_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"multilabel-indicator\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{0} format is not supported\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: multiclass format is not supported"
     ]
    }
   ],
   "source": [
    "keras.backend.clear_session()\n",
    "tbCallBack = keras.callbacks.TensorBoard(log_dir=TENSORBOARD_LOG_DIR,\n",
    " histogram_freq=3,\n",
    " write_grads=True,\n",
    " write_graph=True,\n",
    " write_images=True)\n",
    "\n",
    "# Split the dataset into training and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "  songs, genres, test_size=0.1, stratify=genres)\n",
    "\n",
    "# Split training set into training and validation\n",
    "X_train, X_Val, y_train, y_val = train_test_split(\n",
    "  X_train, y_train, test_size=1/6, stratify=y_train)\n",
    "\n",
    "# split the train, test and validation data in size 128x128\n",
    "X_Val, y_val = AudioUtils().splitsongs_melspect(X_Val, y_val, CNN_TYPE)\n",
    "X_test, y_test = AudioUtils().splitsongs_melspect(X_test, y_test, CNN_TYPE)\n",
    "X_train, y_train = AudioUtils().splitsongs_melspect(X_train, y_train, CNN_TYPE)\n",
    "\n",
    "# Construct the model\n",
    "if CNN_TYPE == '1D':\n",
    "  cnn = ModelZoo.cnn_melspect_1D(input_shape)\n",
    "elif CNN_TYPE == '2D':\n",
    "  cnn = ModelZoo.cnn_melspect_2D((*input_shape, 1))\n",
    "elif CNN_TYPE == 'RNN':\n",
    "  cnn = ModelZoo.crnn_melspect_2D((*input_shape, 1))\n",
    "\n",
    "print(\"\\nTrain shape: {0}\".format(X_train.shape))\n",
    "print(\"Validation shape: {0}\".format(X_Val.shape))\n",
    "print(\"Test shape: {0}\\n\".format(X_test.shape))\n",
    "print(\"Size of the CNN: %s\\n\" % cnn.count_params())\n",
    "\n",
    "# Optimizers\n",
    "if OPTIMIZER == 'sgd':\n",
    "  sgd = keras.optimizers.SGD(lr=0.001, momentum=0.9, decay=1e-5, nesterov=True)\n",
    "elif OPTIMIZER == 'adam':\n",
    "  adam = keras.optimizers.Adam(lr=5e-3) # lr=0.001 #, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=1e-5)\n",
    "\n",
    "# Compiler for the model\n",
    "cnn.compile(loss='binary_crossentropy', #loss=keras.losses.categorical_crossentropy,\n",
    "  optimizer=adam,\n",
    "  metrics=['accuracy'])\n",
    "\n",
    "# Early stop\n",
    "earlystop = keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "  min_delta=0,\n",
    "  patience=2,\n",
    "  verbose=0,\n",
    "  mode='auto')\n",
    "\n",
    "# Fit the model\n",
    "history = cnn.fit(X_train, y_train,\n",
    "  batch_size=batch_size,\n",
    "  epochs=epochs,\n",
    "  verbose=1,\n",
    "  validation_data=(X_Val, y_val),\n",
    "  callbacks = [earlystop])\n",
    "\n",
    "score = cnn.evaluate(X_test, y_test, verbose=0)\n",
    "score_val = cnn.evaluate(X_Val, y_val, verbose=0)\n",
    "\n",
    "# Majority Voting System\n",
    "pred_values = np.argmax(cnn.predict(X_test), axis = 1)\n",
    "mvs_truth, mvs_res = AudioUtils().voting(np.argmax(y_test, axis = 1), pred_values)\n",
    "acc_mvs = accuracy_score(mvs_truth, mvs_res)\n",
    "mvs_roc_auc = roc_auc_score(mvs_truth, mvs_res)\n",
    "\n",
    "# Save metrics\n",
    "val_acc.append(score_val[1])\n",
    "test_acc.append(score[1])\n",
    "test_history.append(history)\n",
    "test_acc_mvs.append(acc_mvs)\n",
    "\n",
    "# Print metrics\n",
    "print('Test accuracy:', score[1])\n",
    "print('Test accuracy for Majority Voting System:', acc_mvs)\n",
    "print('Test auc_roc_score for Majority Voting System:', mvs_roc_auc)\n",
    "\n",
    "# Print the confusion matrix for Voting System\n",
    "cm = confusion_matrix(mvs_truth, mvs_res)\n",
    "print(cm)\n",
    "\n",
    "# Records Best Model\n",
    "if (best_acc < acc_mvs):\n",
    "    best_acc = acc_mvs\n",
    "    best_cnn = cnn\n",
    "    best_history = history\n",
    "    print('best_acc changed:', best_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2, 3, 2, 4, 8, 6, 1, 8, 9, 0, 4, 8, 6, 7, 8, 2, 7, 6, 9, 9, 3, 3,\n",
       "        2, 9, 6, 5, 0, 3, 9, 1, 7, 5, 7, 1, 6, 2, 6, 4, 0, 0, 8, 4, 0, 0,\n",
       "        0, 3, 5, 9, 5, 9, 6, 3, 4, 5, 9, 1, 6, 7, 9, 1, 5, 3, 3, 3, 7, 8,\n",
       "        7, 4, 7, 9, 1, 2, 4, 6, 8, 2, 8, 1, 7, 1, 5, 2, 8, 0, 2, 4, 3, 0,\n",
       "        1, 1, 8, 2, 4, 5, 5, 6, 4, 0, 5, 7]),\n",
       " array([9, 3, 2, 5, 1, 4, 9, 9, 2, 9, 2, 9, 3, 5, 2, 2, 5, 3, 0, 9, 3, 3,\n",
       "        2, 9, 2, 5, 9, 0, 9, 9, 0, 4, 9, 1, 3, 2, 3, 2, 9, 9, 4, 4, 9, 9,\n",
       "        9, 1, 9, 9, 9, 5, 5, 3, 5, 5, 4, 3, 3, 0, 9, 1, 4, 8, 1, 1, 5, 8,\n",
       "        5, 2, 9, 2, 1, 2, 9, 3, 9, 2, 9, 9, 4, 3, 9, 2, 2, 0, 2, 4, 3, 9,\n",
       "        9, 5, 1, 2, 4, 9, 4, 3, 2, 9, 9, 9]))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mvs_truth, mvs_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 5, 5, 9, 9, 9, 9, 9, 5, 9, 3, 3, 3, 1, 1, 1, 0, 0, 0, 3, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 5, 2, 4, 5, 4, 5, 4, 5, 4, 5, 1, 9, 0, 1,\n",
       "       9, 9, 9, 1, 0, 1, 9, 5, 2, 4, 9, 5, 4, 2, 4, 4, 9, 5, 5, 5, 9, 9,\n",
       "       5, 9, 0, 9, 9, 8, 9, 8, 9, 8, 9, 9, 9, 8, 2, 4, 2, 4, 2, 2, 2, 2,\n",
       "       2, 4, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 2, 4, 4, 4, 2, 2, 2, 2, 4, 2,\n",
       "       0, 5, 9, 9, 5, 1, 9, 1, 9, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 0, 5, 9,\n",
       "       4, 5, 5, 5, 4, 5, 4, 4, 2, 2, 2, 2, 5, 5, 4, 4, 4, 9, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 9, 4, 4, 5, 5, 5, 9, 5, 9, 2, 3, 3, 3, 3, 3, 3,\n",
       "       3, 1, 3, 3, 0, 9, 0, 3, 0, 9, 1, 0, 3, 9, 5, 5, 9, 9, 9, 5, 4, 9,\n",
       "       2, 9, 1, 3, 3, 1, 3, 3, 3, 1, 3, 3, 3, 3, 3, 9, 3, 0, 3, 3, 0, 3,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 9, 5, 9, 9, 5, 9, 9, 5, 9, 9, 4, 2,\n",
       "       4, 2, 2, 2, 4, 2, 2, 2, 5, 9, 5, 5, 5, 5, 9, 9, 9, 5, 9, 9, 9, 9,\n",
       "       9, 9, 9, 9, 9, 9, 0, 0, 0, 0, 1, 1, 1, 9, 0, 1, 5, 9, 9, 9, 9, 5,\n",
       "       9, 5, 9, 9, 1, 1, 9, 9, 9, 0, 9, 0, 0, 9, 0, 0, 1, 0, 0, 3, 3, 0,\n",
       "       1, 0, 5, 4, 5, 5, 4, 5, 4, 4, 9, 9, 9, 9, 9, 9, 9, 5, 9, 4, 4, 5,\n",
       "       0, 9, 1, 0, 1, 3, 1, 1, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 1, 3, 1, 3, 1, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 5, 9, 0, 9, 5, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 5,\n",
       "       5, 9, 9, 4, 5, 9, 4, 9, 4, 4, 2, 2, 8, 8, 5, 5, 5, 5, 4, 4, 4, 4,\n",
       "       5, 4, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 5, 5, 9, 9, 9, 9, 9, 9, 9,\n",
       "       9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 3, 1, 1, 1, 1, 3, 3, 1, 9, 3, 8, 9,\n",
       "       9, 5, 5, 9, 4, 5, 9, 9, 9, 9, 9, 0, 9, 9, 0, 9, 9, 0, 9, 9, 5, 9,\n",
       "       9, 9, 9, 9, 5, 9, 5, 5, 5, 5, 9, 5, 5, 5, 5, 5, 9, 5, 5, 4, 5, 5,\n",
       "       5, 5, 5, 5, 3, 3, 3, 3, 3, 3, 1, 3, 1, 1, 5, 5, 5, 5, 5, 9, 5, 5,\n",
       "       4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 2, 2, 4, 4, 4, 5, 5, 4, 9, 2,\n",
       "       3, 3, 3, 0, 1, 3, 1, 1, 0, 3, 5, 3, 1, 3, 1, 3, 1, 3, 0, 9, 9, 9,\n",
       "       0, 0, 0, 0, 9, 0, 9, 9, 9, 9, 9, 3, 9, 9, 1, 9, 8, 1, 9, 9, 0, 9,\n",
       "       0, 1, 1, 9, 1, 1, 4, 5, 4, 4, 4, 4, 5, 4, 5, 4, 3, 1, 8, 8, 3, 8,\n",
       "       8, 8, 8, 1, 1, 8, 1, 9, 9, 1, 3, 1, 8, 9, 3, 1, 1, 0, 9, 0, 9, 1,\n",
       "       0, 1, 4, 5, 4, 9, 5, 4, 5, 5, 5, 4, 2, 4, 8, 8, 9, 3, 4, 8, 9, 8,\n",
       "       5, 5, 5, 5, 2, 4, 4, 5, 5, 4, 2, 2, 4, 2, 2, 2, 2, 2, 2, 2, 0, 9,\n",
       "       0, 9, 9, 9, 9, 9, 9, 9, 4, 2, 2, 2, 2, 4, 8, 2, 4, 4, 8, 0, 0, 1,\n",
       "       1, 1, 0, 1, 1, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 9, 5, 9, 9, 9, 5,\n",
       "       9, 5, 5, 9, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 8, 1, 8, 8, 9, 9, 9, 9,\n",
       "       1, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 5, 9, 9, 9, 5, 5, 9, 9, 9, 9,\n",
       "       9, 9, 9, 9, 9, 5, 9, 9, 5, 9, 4, 5, 4, 2, 2, 4, 2, 4, 4, 4, 3, 8,\n",
       "       3, 6, 3, 1, 6, 8, 1, 3, 9, 9, 9, 9, 9, 9, 9, 9, 5, 9, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 9, 0, 0,\n",
       "       9, 9, 9, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 4, 5, 5, 4, 4, 4, 4,\n",
       "       5, 4, 1, 9, 0, 0, 9, 3, 1, 3, 3, 3, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9,\n",
       "       9, 8, 9, 9, 9, 8, 1, 9, 9, 9, 9, 5, 9, 5, 5, 5, 5, 5, 5, 5, 1, 1,\n",
       "       1, 8, 8, 1, 1, 1, 8, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 5, 4, 5, 4,\n",
       "       5, 4, 5, 4, 4, 5, 9, 9, 9, 9, 9, 9, 9, 9, 5, 9, 9, 4, 5, 4, 5, 4,\n",
       "       4, 9, 5, 5, 6, 3, 1, 3, 1, 1, 3, 0, 3, 3, 4, 5, 4, 4, 5, 4, 2, 2,\n",
       "       2, 2, 9, 9, 5, 9, 9, 9, 9, 9, 9, 9, 4, 9, 9, 9, 9, 9, 9, 9, 9, 9,\n",
       "       0, 9, 9, 9, 1, 9, 9, 9, 9, 9])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#np.argmax(y_test, axis = 1)\n",
    "pred_values = np.argmax(cnn.predict(X_test), axis = 1)\n",
    "pred_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_values =cnn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0., 0., 1., ..., 0., 0., 0.],\n",
       "        [0., 0., 1., ..., 0., 0., 0.],\n",
       "        [0., 0., 1., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 1., 0., 0.],\n",
       "        [0., 0., 0., ..., 1., 0., 0.],\n",
       "        [0., 0., 0., ..., 1., 0., 0.]]),\n",
       " array([[0.1236752 , 0.04578517, 0.05659752, ..., 0.19004093, 0.07126129,\n",
       "         0.21616907],\n",
       "        [0.10009772, 0.04310775, 0.0605137 , ..., 0.16417207, 0.07075483,\n",
       "         0.17629012],\n",
       "        [0.10974169, 0.04142744, 0.0705883 , ..., 0.1844229 , 0.06655623,\n",
       "         0.200849  ],\n",
       "        ...,\n",
       "        [0.16567132, 0.07175727, 0.0189496 , ..., 0.1634024 , 0.09061007,\n",
       "         0.21569157],\n",
       "        [0.14766963, 0.05910565, 0.03124412, ..., 0.1842281 , 0.08690333,\n",
       "         0.22420873],\n",
       "        [0.19126137, 0.13312256, 0.00873672, ..., 0.12118168, 0.11524045,\n",
       "         0.19143613]], dtype=float32))"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test, pred_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7527016666666666"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test, pred_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
